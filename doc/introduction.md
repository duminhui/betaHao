# 写在前面

本repo只具备了算法思路和串行方式的实现，但并未验证任何算法效果，及测试代码正确性。且数据的输入输出骗码，和神经元在输出结点上的的逆向反馈仍需编写。

# 设计思路：

生物普遍通过神经细胞组成网络，并在此基础上拥有功能。本repo并未试图直接寻找人的智能，即实现人类层面的思考，而是试图挖掘名种生物神经网络之间的普遍的工作规律，以此来设计神经网络算法。也就是说，本repo的重点放在了单个神经元的工作机制，和外部数据对网络的影响上。当然不排除整个设计思路的错误。其次，未来可以加入特定的神经元链接机制，和有目的的设计网络模块，并以此来达到所谓人的智能，这些想法的成因都在最后的思考中给出。

众所周知，如果把神经网络看作一个黑盒，特定的外部数据引起特定的神经元的兴奋，最终神经网络将神经元兴奋转换为肌肉的收缩等一系列输出。从电压的角度看，神经元传递的信号随时间不规律变化，包含尖峰状的脉冲(spike)的同时，也在神经元之间的轴突末端将电信号转为了化学递质的释放。总的来说，是电信号->化学信号->另一神经元电信号的转换。但不仅神经元上不同位置的电信号并不相同，而且很难想象在神经元在生长过程中对在电信号层面保持对外部同一事物的记忆和学习。若再结合能量消耗等，会使整个过程建模起来非常复杂。因此，我认为并不是所有的电信号输入都是有意义的。为简化问题，结合粗浅的生物学认识，我选择从电信号对后端神经元的作用入手，使电信号随时间步进离散化（一些卷积的思想，但没那么复杂）。为此，我选择2种结果作为电信号的分类：使得化学递质足量释放，未使化学递质足量释放。这里的足量是一个模糊的概念，可粗略把对后端神经元产生尖峰脉冲(spike)，或足够的抑制低压看作足量的尺度。至此，我只要考虑当前时刻电信号对后端的影响，而不用考虑一个看似随机的信号图。再结合化学递质分为兴奋和抑制两种，结果可以把一个神经元，通过神经递质对另一神经元电信号的影响结果，分为四类：足量兴奋(excited，释放兴奋递质并使后端神经元激发)、未足量兴奋(unexcited，释放兴奋递质但未使后端神经元激发或未释放递质)、未足量抑制(uninhibited，释放抑制递质但未使后端神经元产生抑制或未释放递质)、足量抑制(inhibited，释放抑制递质并产生抑制)。注意这里只考虑的是单一时刻的影响，或者说单位时间内或单一时间步进内的影响。

显然，单单只有神经动作电位是不足以调节功能的，它只会在能量充足的情况下使得神经元兴奋一直持续下去。其次，神经网络的能量应该是充欲的。单个神经元长时间集中兴奋消耗过多能量的情况并不多见；并且工作最频繁的心脏消耗着能量，也未遇到能量不足的情况；神经网络应该是具拥有富余能量后进化的组织。因此从能量限制神经元功能的角度入手是不正确的。相比之下，神经递质是神经元完成功能的关键。它决定了哪一刻的电信号是否转为下一个神经元的电信号兴奋或抑制。而最直观的考量是神经递质的量：量是多少，什么决定了它的量，它的量又影响了什么。神经元作为蛋白质，必然参与到蛋白质调节中。而蛋白质调节是复杂的，在尝试从简单的阴阳离子代谢的角度无法回答上述问题后，这就需要从其它角度思考神经递质的量与作用。

只能做到以神经递质乙酰胆碱为例，作一个假设和推理。它作为一种常见的兴奋递质，通过神经兴奋被后端神经元接收后，会使后端神经元内阴离子增加，在不过量的情况下，从而更容易恢复内负外正的静置电位，也就意味着后端神经元更容易恢复兴奋。何谓更客易恢复兴奋，即为某个时间段内兴奋次数增加的可能，也即单次兴奋的概率增加，这很关键。

那么这种单次兴奋的概率增加是否具有现实意义？可以想象，在神经网络进化初期，许多可以产生电信号的神经细胞聚集在一起。在外部的众多输入中，经常发生的事物和突发事件通常更容易被传递的话，他们更容易让物种适应环境，从而得以保留。若一个事物经常发生，在频繁刺激同样的神经元后它理论上可以使有限神经网络下所有的神经元兴奋，即更容易把该事物传播出去。这种单次兴奋下的概率增加，使得外部事物在其发生频次上得以竞争。其次，再想要从现实意义中挖掘些有意义的思路，变的不那么容易。唯一可能的假设是并不是所有的常见事物都有用处。那么就必然需要从输出端神经元起，存在抑制前端神经元的过程，即逆向反馈。如果，某些常见事物的输入不能引起正确和适应环境的输出，那么该神经细胞引起的兴奋应当减弱，即导致兴奋概率的下降。那这种兴奋概率的下降的逆向反馈是否有可能的生理基础？答案是肯定的。当输出神经元遇到阻碍(比如同一神经元同时引起一对拮抗肌肉神经元兴奋)，或未引起后端神经元兴奋时，神经递质会在轴突外部引起聚集而参与到前端神经元的代谢中，这种聚集会导致前端神经元轴突产生神经递质的时间和量变慢减少，即兴奋概率下降。

由此可见，单次兴奋导致后端神经元兴奋概率的增加，实际上完成的是单一事物记忆的功能。事实上，神经网络还要解决了一个关联记忆的功能，即表征稳定联系的相关事件。什么是稳定联系？为了给出一个神经网络下的解释，只能把概念定义的模糊些，即存在小范围时间差内的存在相关关系的事件。这样的关系同样可以用概率表征。设想一下，两个关联关系经过若干神经元后，连接到了同一个神经元上，那么经过这个神经元后的神经元，所表征的就是两事件的关联关系。它仍可被概率度量。两个同时兴奋的轴突作用到同一后端神经元上时，会引起后端神经元的必然兴奋，这种挖掘事物之间关联性的规则被称为Hebb规则。无论这种必然兴奋是神经递质调节的过程，还是调节的结果，我们都可以把同周期内的Hebb事件看作必然兴奋的事件，把它运用到接下来要介绍的神经元的机制中。当然除了Hebb规则，神经元之间还存在掩蔽效应，即在后端神经元兴奋后的一段时间内，其无法再接收其前端神经元传来的兴奋。虽然这种现象所表现的现实意义并不明确，但这并不妨碍我们作出假设：假设掩蔽效应阶段下兴奋的神经元，其神经递质同样表现为在轴突外部产生堆积，使得前端神经元的兴奋概率减小。

至此，使得神经元兴奋概率增加和减小的因素都存在了，那么抽象出来的神经网络就可以在外部刺激的逆向反馈的作用下，完成神经网络的学习与记忆。

# 程序设计与改进

本repo设计的神经元组件(Neuron)拥有若干轴突分支(Branch)。每个轴突分支相互独立，记录一个兴奋概率(probability)，和后端所连接的神经元(next)。当该神经元兴奋后，遍历每个轴突分支，通过binaration()函数以其各自的兴奋概率（probability)产生后端神经元的兴奋状态(Excited, Unexcited, UnInhibited, Inhibited)。根据兴奋状态来判断神经递质是否被后端神经元接收，执行impulse()，从而决定当前轴突分支的兴奋概率增加或减少。由于Hebb规则和掩蔽效应的存在，这两个效应与时间(步进step)相关，因此，还需在神经元组件(Neuron)中记录下上次触发(touch)该神经元的前端神经元的轴突分支记录(register_of_previous_touch)，才能完善binaration()函数的判断。前端神经元记录包括上次兴奋的前轴突分支(branch)、上次兴奋概率(probability)，上次兴奋状态(state)、上次兴奋的时间步进(step)。每次要根据上次兴奋状态(state)与上次步进之间的时间差( δstep)，来选择不同的状态生成方式。具体生成方式如下：

当br.p>0时，后端神经元兴奋的结果(result)：

|         | last.state=Excited                                           | Unexcited                                                    | Uninhibited                                                  | Inhibited                                                    |
| ------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| δstep=0 | p=1<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | 同左                                                         | p=last.p+br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | p=br.p-1<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 |
| 0-3     | 进入掩蔽期<br />br.Decrease()<br />不注册                    | p=last.p+br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | 同左                                                         | 同左                                                         |
| 3-      | p=br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | 同左                                                         | 同左                                                         | 同左                                                         |

当br.p<0时，后端神经元兴奋的结果：

|         | last.state=Excited                                           | Unexcited                                                    | Uninhibited                                                  | Inhibited                                 |
| ------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------- |
| δstep=0 | p=1+br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | p=last.p+br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | p=-1<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | 同左                                      |
| 0-3     | p=last.p+br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | 同左                                                         | 同左                                                         | 进入掩蔽期<br />br.Increase()<br />不注册 |
| 3-      | p=br.p<br />二值化(p)<br />根据二值化结果增减br.p<br />注册神经元到后端寄存器 | 同左                                                         | 同左                                                         | 同左                                      |

关于表格的几点说明：

1. 二值化函数binaration()只是字面意思，因为p的范围是[-1,1]，在二值化的过程中要考虑到正负
2. 增减二值化结果的impulse()函数同理
3. br.Decrease()、br.Increase()同理

有了根据轴突分支概率(br.p)生成后端兴奋状态的函数touch()之后，我们就可以考虑运行态的情形。维护一个队列：

1. 维护一个队列queue
2. 在每个时间步进开始时：
   1. 放入一个空神经元节点到队列中，作为不同时间步进(step)的区分
   2. 放入有兴奋的外部输入节点
   3. 读取有兴奋的输出节点
3. 读取队列顶端元素：
   1. 若是空节点，重复操作2
   2. 若不是空节点且当前神经元state=Excited，对每一个轴突分支(branch)执行touch()函数，若执行结果位Excited，则将后端神经元节点放入队列

值得思考的是神经元节点在初始化时，轴突分支的概率(br.p)初始化为0，因此网络兴奋需要从输入端开始兴奋。也可以尝试将轴突分支的概率(br.p)初始化为0，在输出端的逆向反馈和神经元相互作用之中一直神经元的兴奋。

# 一些未在算法中体现的思考

1. 人类大脑折叠与数据流向

根据一些大脑神经发育的书籍来看，我认为大脑由于空间限制，在发育过程中发生了折叠，总的来说是C字型。C的起笔位置是大脑的后端，是大脑的起点，连接着视觉、听觉输入。在C的末笔前连接着脑干，维持这心跳、呼吸等生理功能的神经活动。C的末笔是小脑，控制着运动肌肉的精细调节。由此不难看出，外部输入的数据流向是从脑上后端开始，向前传播，最终又回到了脑的下后端。数据流向重复着这样的C型，且越往脑前端，越是经过Hebb规则与掩蔽效应概括的内容，也越抽象。

2. 心脏等固定周期的数据输入可能决定事物与时间的关联性

心脏是拥有规律运动的器官，附着在其上的触觉神经元收到的电信号也是随时间规律变化的，这些信号经过脑干到达大脑底部，于是更容易在全大脑的垂直方向与所有神经元发生联系。这样，如果一个事物与时间变化密切相关，那么它更有可能与脑干传到大脑的神经元，在垂直方向的连接加强联系。

3. 轴突分支的数量和连接是否可以被调节

在本repo的算法中，轴突分支连接的目标和数量都是随机或人为规定的。但事实上，并不能排除有选择性连接的可能。首先，若轴突更容易向着电位高(正负电位的相互吸引)的地方生长的理论成立，那么轴突会优先选择一些不经常兴奋的神经元树突进行连接。其次，若经常兴奋的神经元更容易产生轴突分支的话，那么轴突分支的数量就拥有个体的选择性差异，这种差异没有考虑到算法中的话，无法估计会产生多大的影响。

4. 神经激素的调节被忽视

本repo的算法中，神经激素的调节被忽视。由于能力有限，我没有更多知识了解到神经激素的作用范围，作用条件等信息。因此对我来说神经激素能起到什么样的作用，它是否会有规律的，在较长时间范围内整体改变某一个区域内神经元电信号的兴奋，这是一个值得思考的问题。